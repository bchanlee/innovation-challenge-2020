{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "snapshot.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bclee232/vaccine-twitter-sentiment/blob/master/albert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "scrolled": false,
        "trusted": true,
        "id": "wk-68jSpyjJU",
        "colab_type": "code",
        "colab": {},
        "outputId": "caff30b2-37ec-4c98-ef26-1f67175d9d81"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/kaggle/lib/kaggle/gcp.py\n",
            "/kaggle/input/bert-chinese/bert_model.ckpt.index\n",
            "/kaggle/input/bert-chinese/bert_model.ckpt.data-00000-of-00001\n",
            "/kaggle/input/bert-chinese/bert_model.ckpt.meta\n",
            "/kaggle/input/snapshots/snapshot_model_1.h5\n",
            "/kaggle/input/snapshots/snapshot_model_2.h5\n",
            "/kaggle/input/snapshots/snapshot_model_3.h5\n",
            "/kaggle/input/snapshots/snapshot_model_4.h5\n",
            "/kaggle/input/snapshot/snapshot_model_1.h5\n",
            "/kaggle/input/innovation/hydrated_data_training.csv\n",
            "/kaggle/input/innovation/data_training.csv\n",
            "/kaggle/input/innovation/hydrated_data_test.csv\n",
            "/kaggle/working/__notebook_source__.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "S5VGjIj8yjKY",
        "colab_type": "code",
        "colab": {},
        "outputId": "0efdb9e9-2c69-4de6-9c12-9af351ff44b7"
      },
      "source": [
        "data = pd.read_csv('/kaggle/input/innovation/data_training.csv')\n",
        "hydrated_data = pd.read_csv('/kaggle/input/innovation/hydrated_data_training.csv')\n",
        "test_data = pd.read_csv('/kaggle/input/innovation/hydrated_data_test.csv')\n",
        "\n",
        "zero, one = data.tweet_label_int.value_counts()\n",
        "print(zero, one, zero/(zero + one) * 100) # 88% 0 12% 1\n",
        "\n",
        "tweet_label_int = data.tweet_label_int\n",
        "tweet_label_list = tweet_label_int.tolist()\n",
        "tweetid = data.tweetid\n",
        "tweetid_list = tweetid.tolist()\n",
        "\n",
        "hydrated_tweetid = hydrated_data.id\n",
        "hydrated_tweetid_list = hydrated_tweetid.tolist()\n",
        "\n",
        "labels = []\n",
        "\n",
        "for i in range(len(hydrated_tweetid_list)):\n",
        "    val = int(hydrated_tweetid_list[i])\n",
        "    for j in range(len(tweetid_list)):\n",
        "        if val == int(tweetid_list[j]):\n",
        "            labels.append(float(tweet_label_list[j]))\n",
        "            break\n",
        "\n",
        "print(len(labels), labels[0:10])\n",
        "hydrated_data['labels'] = labels\n",
        "print(hydrated_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7915 1085 87.94444444444444\n",
            "8351 [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "(8351, 35)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Uxtmvp-VyjKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({'text': hydrated_data.text, 'tweet_label_int': labels, 'lang': hydrated_data.lang})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BaPVRqRQyjKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = df[df.lang == 'en'].reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "D6e_IxKkyjKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cAzT25EcyjKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CONTRACTION_MAP = {\n",
        "\"ain't\": \"is not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he'll've\": \"he he will have\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"I'd\": \"I would\",\n",
        "\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I will\",\n",
        "\"I'll've\": \"I will have\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"i'd\": \"i would\",\n",
        "\"i'd've\": \"i would have\",\n",
        "\"i'll\": \"i will\",\n",
        "\"i'll've\": \"i will have\",\n",
        "\"i'm\": \"i am\",\n",
        "\"i've\": \"i have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it'll've\": \"it will have\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she'll've\": \"she will have\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as\",\n",
        "\"that'd\": \"that would\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they'll've\": \"they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what'll've\": \"what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who'll've\": \"who will have\",\n",
        "\"who's\": \"who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you'll've\": \"you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rQzHjjf7yjKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preprocessing\n",
        "import re\n",
        "import nltk\n",
        "import spacy\n",
        "import string\n",
        "\n",
        "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
        "    \n",
        "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
        "                                      flags=re.IGNORECASE|re.DOTALL)\n",
        "    def expand_match(contraction):\n",
        "        match = contraction.group(0)\n",
        "        first_char = match[0]\n",
        "        expanded_contraction = contraction_mapping.get(match)\\\n",
        "                                if contraction_mapping.get(match)\\\n",
        "                                else contraction_mapping.get(match.lower())                       \n",
        "        expanded_contraction = first_char+expanded_contraction[1:]\n",
        "        return expanded_contraction\n",
        "        \n",
        "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
        "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
        "    return expanded_text\n",
        "\n",
        "def remove_at(text):\n",
        "    text = text.split()\n",
        "    list = []\n",
        "    for i in text:\n",
        "        if \"@\" not in i:\n",
        "            list.append(i)\n",
        "    return ' '.join(list)\n",
        "\n",
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', string)\n",
        "\n",
        "def remove_urls(text):\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url_pattern.sub(r'', text)\n",
        "\n",
        "def remove_hash(text):\n",
        "    \"\"\"custom function to remove the punctuation\"\"\"\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "pre_data = data\n",
        "pre_data[\"text\"] = data[\"text\"].apply(lambda text: expand_contractions(text))\n",
        "pre_data[\"text\"] = pre_data[\"text\"].apply(lambda text: remove_at(text))\n",
        "pre_data[\"text\"] = pre_data[\"text\"].apply(lambda text: remove_emoji(text))\n",
        "pre_data[\"text\"] = pre_data[\"text\"].apply(lambda text: remove_urls(text))\n",
        "pre_data[\"text\"] = pre_data[\"text\"].apply(lambda text: remove_hash(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rQxa7Nb7yjKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hz36_UTMyjKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = np.array(hydrated_data['labels']).astype('int')\n",
        "print(train_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oKuoyXVXyjK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_test = pd.DataFrame({'text': test_data.text, 'lang': test_data.lang})\n",
        "pre_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ruazDBaqyjK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_test[\"text\"] = pre_test[\"text\"].apply(lambda text: expand_contractions(text))\n",
        "pre_test[\"text\"] = pre_test[\"text\"].apply(lambda text: remove_at(text))\n",
        "pre_test[\"text\"] = pre_test[\"text\"].apply(lambda text: remove_emoji(text))\n",
        "pre_test[\"text\"] = pre_test[\"text\"].apply(lambda text: remove_urls(text))\n",
        "pre_test[\"text\"] = pre_test[\"text\"].apply(lambda text: remove_hash(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "U_c1t56ByjK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3-F4GH_RyjK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_text = hydrated_data['text'].astype(str)\n",
        "test_data_text = test_data['text'].astype(str)\n",
        "print(train_data_text, test_data_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "trusted": true,
        "id": "ZQGOwKhDyjLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def meta_text(text):\n",
        "    data_text_len = [len(x) for x in text]\n",
        "    return (data_text_len[np.argmax(data_text_len)], data_text_len[np.argmin(data_text_len)], np.mean(data_text_len))\n",
        "print(\"train\", meta_text(train_data_text), \"test\", meta_text(test_data_text)) # max, min, mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "trusted": true,
        "id": "k2PrEuwUyjLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zero, one = np.bincount(train_labels)\n",
        "total_count = len(train_labels)\n",
        "weight_zero = (1 / zero) * (total_count) / 2.0\n",
        "weight_one = (1 / one) * (total_count) / 2.0\n",
        "class_weights = {0: weight_zero, 1: weight_one}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "trusted": true,
        "id": "AWqtRT93yjLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(total_count, zero, one)\n",
        "print(class_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "izl5QsXnyjLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import transformers\n",
        "t_albert = transformers.AlbertTokenizer.from_pretrained('albert-large-v2', do_lower_case=True) # resource exhausted using xxlarge\n",
        "albert_model = transformers.TFAlbertModel.from_pretrained('albert-large-v2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "trusted": true,
        "id": "a3NntL9GyjLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def albert_encode(data, max_len, t):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for i in range(len(data)):\n",
        "        encoded = t.encode_plus(data[i],\n",
        "                               add_special_tokens=True,\n",
        "                               max_length=max_len,\n",
        "                               pad_to_max_length=True,\n",
        "                               return_attention_mask=True)\n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_masks.append(encoded['attention_mask'])\n",
        "    return np.array(input_ids), np.array(attention_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "trusted": true,
        "id": "TeehgLWoyjLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input_ids, train_attention_masks = albert_encode(train_data_text, 100, t_albert) # 100\n",
        "x_train = [train_input_ids[1600:], train_attention_masks[1600:]]\n",
        "y_train = train_labels[1600:]\n",
        "x_val = [train_input_ids[:1600], train_attention_masks[:1600]]\n",
        "y_val = train_labels[:1600]\n",
        "test_input_ids, test_attention_masks = albert_encode(test_data_text, 100, t_albert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHFpSDmBSGmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "trusted": true,
        "id": "JSRIvXk-yjLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from keras.layers import LSTM,  Embedding, BatchNormalization, Dense, TimeDistributed, Dropout, Bidirectional, Flatten, GlobalMaxPool1D\n",
        "\n",
        "def create_biLSTM(albert_model):\n",
        "    \n",
        "    input_ids = Input(shape=(100,), dtype='int32')\n",
        "    attention_masks = Input(shape=(100,), dtype='int32')\n",
        "    \n",
        "    output = albert_model([input_ids, attention_masks])\n",
        "    output = output[0] # get embeddings - not [1]\n",
        "    output = Bidirectional(LSTM(32, dropout=0.1, recurrent_dropout=0.5))(output) # changed to 16\n",
        "    output = Dense(1, activation='sigmoid')(output)\n",
        "\n",
        "    model = Model(inputs = [input_ids, attention_masks], outputs=output)\n",
        "    model.compile(Adam(lr=6e-6), loss='binary_crossentropy', metrics=[f1_score])\n",
        "    \n",
        "    return model\n",
        "\n",
        "def create_model(albert_model):\n",
        "    input_ids = Input(shape=(100,),dtype='int32')\n",
        "    attention_masks = Input(shape=(100,), dtype='int32')\n",
        "    \n",
        "    output = albert_model([input_ids, attention_masks])\n",
        "    output = output[1]\n",
        "    output = Dense(1, activation='sigmoid')(output)\n",
        "    model = Model(inputs = [input_ids, attention_masks], outputs=output)\n",
        "    model.compile(Adam(lr=6e-6), loss='binary_crossentropy', metrics=[f1_score])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "trusted": true,
        "id": "h_kooekyyjLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import h5py\n",
        "\n",
        "es = EarlyStopping(monitor='val_f1_score',mode='max',verbose=1, patience=5)\n",
        "checkpoint = ModelCheckpoint(\"best_model.hdf5\", monitor='val_f1_score', verbose=1, save_best_only=True, mode='max', period=1)\n",
        "callbacks = [es, checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_oesscm-yjLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_biLSTM(albert_model)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kilkxnXEyjLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "from math import pi\n",
        "from math import cos\n",
        "from math import floor\n",
        "from keras import backend\n",
        "\n",
        "# snapshot ensemble with custom learning rate schedule\n",
        "class SnapshotEnsemble(Callback):\n",
        "    # constructor\n",
        "    def __init__(self, n_epochs, n_cycles, lrate_max, verbose=0):\n",
        "        self.epochs = n_epochs\n",
        "        self.cycles = n_cycles\n",
        "        self.lr_max = lrate_max\n",
        "        self.lrates = list()\n",
        " \n",
        "    # calculate learning rate for epoch\n",
        "    def cosine_annealing(self, epoch, n_epochs, n_cycles, lrate_max):\n",
        "        epochs_per_cycle = floor(n_epochs/n_cycles)\n",
        "        cos_inner = (pi * (epoch % epochs_per_cycle)) / (epochs_per_cycle)\n",
        "        return lrate_max/2 * (cos(cos_inner) + 1)\n",
        " \n",
        "    # calculate and set learning rate at the start of the epoch\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        # calculate learning rate\n",
        "        lr = self.cosine_annealing(epoch, self.epochs, self.cycles, self.lr_max)\n",
        "        # set learning rate\n",
        "        backend.set_value(self.model.optimizer.lr, lr)\n",
        "        # log value\n",
        "        self.lrates.append(lr)\n",
        " \n",
        "    # save models at the end of each cycle\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        # check if we can save model\n",
        "        epochs_per_cycle = floor(self.epochs / self.cycles)\n",
        "        if epoch != 0 and (epoch + 1) % epochs_per_cycle == 0:\n",
        "            # save model to file\n",
        "            filename = \"/kaggle/working/snapshot_model_%d.h5\" % int((epoch + 1) / epochs_per_cycle)\n",
        "            self.model.save_weights(filename)\n",
        "            print('>saved snapshot %s, epoch %d' % (filename, epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wnMxr7s6yjLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create snapshot ensemble callback\n",
        "n_epochs = 20\n",
        "n_cycles = n_epochs / 5\n",
        "ca = SnapshotEnsemble(n_epochs, n_cycles, 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5A0zfto4yjLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = [train_input_ids[1600:], train_attention_masks[1600:]]\n",
        "y_train = train_labels[1600:]\n",
        "x_val = [train_input_ids[:1600], train_attention_masks[:1600]]\n",
        "y_val = train_labels[:1600]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1xCPyme5yjLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist = model.fit(x_train, \n",
        "                 y_train,\n",
        "                 epochs=n_epochs,\n",
        "                 batch_size=32,\n",
        "                 class_weight=class_weights,\n",
        "                validation_data=(x_val, y_val),\n",
        "                callbacks=[ca])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nRKMNRWeyjLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"hist = model.fit([train_input_ids, train_attention_masks], \n",
        "                 train_labels,\n",
        "                 epochs=1,\n",
        "                 batch_size=32,\n",
        "                 validation_split=0.2,\n",
        "                 class_weight=class_weights,\n",
        "                callbacks=callbacks)\"\"\" # 14"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SEMDaJPayjLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load models and make a snapshot ensemble prediction\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from matplotlib import pyplot\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import numpy\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "\n",
        "# load models from file\n",
        "def load_all_models(n_models):\n",
        "    all_models = list()\n",
        "    for i in range(n_models):\n",
        "        # define filename for this ensemble\n",
        "        filename = 'snapshot_model_' + str(i + 1) + '.h5'\n",
        "        # load model from file\n",
        "        model = load_model(filename)\n",
        "        # add to list of members\n",
        "        all_models.append(model)\n",
        "        print('>loaded %s' % filename)\n",
        "    return all_models\n",
        "\n",
        "# make an ensemble prediction for multi-class classification\n",
        "def ensemble_predictions(members, testX):\n",
        "    # make predictions\n",
        "    yhats = [model.predict(testX) for model in members]\n",
        "    yhats = array(yhats)\n",
        "    # sum across ensemble members\n",
        "    summed = numpy.sum(yhats, axis=0)\n",
        "    # argmax across classes\n",
        "    result = argmax(summed, axis=1)\n",
        "    return result\n",
        "\n",
        "# evaluate a specific number of members in an ensemble\n",
        "def evaluate_n_members(members, n_members, testX, testy):\n",
        "    # select a subset of members\n",
        "    subset = members[:n_members]\n",
        "    # make prediction\n",
        "    yhat = ensemble_predictions(subset, testX)\n",
        "    # calculate accuracy\n",
        "    return accuracy_score(testy, yhat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRvs8v2QULfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = model.predict([test_input_ids, test_attention_masks])\n",
        "result = np.round(result).astype(int)\n",
        "res_list = result.flatten().tolist()\n",
        "output = pd.DataFrame({'tweetid': test_data.id, 'tweet_label_int': res_list})\n",
        "output.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}